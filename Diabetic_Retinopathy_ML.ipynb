{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SheryllD/diabetic_retinopathy_ml/blob/main/Diabetic_Retinopathy_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUjZZU8Pd-YO"
      },
      "source": [
        "# EDA Analysis | Diabetic Retinopathy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeiLmxSXAvVk"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UonQ-rYKHklX"
      },
      "outputs": [],
      "source": [
        "# Install Kaggle API\n",
        "!pip install Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZb1UUvk20wl",
        "outputId": "cb9cb90d-6446-4b4d-b670-b0540ad7348a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 222, in iter_dependencies\n",
            "    req = Requirement(req_string.strip())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/requirements.py\", line 36, in __init__\n",
            "    parsed = _parse_requirement(requirement_string)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 62, in parse_requirement\n",
            "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_tokenizer.py\", line 104, in __init__\n",
            "    self.rules: dict[str, re.Pattern[str]] = {\n",
            "                                             ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_tokenizer.py\", line 104, in <dictcomp>\n",
            "    self.rules: dict[str, re.Pattern[str]] = {\n",
            "                                             ^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1230, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 119, in format\n",
            "    prefix += \" \" * get_indentation()\n",
            "                    ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 69, in get_indentation\n",
            "    def get_indentation() -> int:\n",
            "    \n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python # For colour enhancement preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR8CSCubFdJL"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79-Xar2JFW4t",
        "outputId": "4085920e-b544-423d-8ce4-2b56f0c34ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Necessary modules have been imported\n"
          ]
        }
      ],
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"Necessary modules have been imported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNXc0BJPHum6"
      },
      "source": [
        "## 2. Mount Drive and Set up Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NpEUc1okjaF",
        "outputId": "bc01d434-c89c-4521-dd5c-6e850b6aa6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset URL: https://www.kaggle.com/datasets/tanlikesmath/diabetic-retinopathy-resized\n",
            "License(s): unknown\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/Keys/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d tanlikesmath/diabetic-retinopathy-resized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqdD5MpTF8aw"
      },
      "source": [
        "## 3. Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDDiywl4n7iz"
      },
      "outputs": [],
      "source": [
        "# Importing kaggle\n",
        "import kagglehub\n",
        "\n",
        "# Downloading latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"tanlikesmath/diabetic-retinopathy-resized\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPjXncJbA7h8"
      },
      "source": [
        "### Dataset Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDcVKMsWpRmn"
      },
      "outputs": [],
      "source": [
        "# Reviewing the paths\n",
        "print(\"Downloaded path:\", path)\n",
        "print(\"Contents of the folder:\")\n",
        "print(os.listdir(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6se368yjpxm"
      },
      "outputs": [],
      "source": [
        "# Function to get the correct base path.\n",
        "\n",
        "def get_valid_base_path():\n",
        "  path_1 = \"/root/.cache/kagglehub/datasets/tanlikesmath/diabetic-retinopathy-resized/versions/7\"\n",
        "  path_2 = \"/kaggle/input/diabetic-retinopathy-resized\"\n",
        "  if os.path.exists(path_1):\n",
        "    return path_1\n",
        "  elif os.path.exists(path_2):\n",
        "    return path_2\n",
        "  else:\n",
        "    raise ValueError(\"No valid base path found.\")\n",
        "\n",
        "# Using the valid base path\n",
        "base_path = get_valid_base_path()\n",
        "print(\"Contents:\", os.listdir(base_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgo6CdasIMHS"
      },
      "source": [
        "### Load and Clean CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoW4QbILr4zS"
      },
      "outputs": [],
      "source": [
        "# I am using the cropped images to reduce the noise\n",
        "\n",
        "df_images = os.path.join(base_path, \"resized_train_cropped\", \"resized_train_cropped\")\n",
        "labels = os.path.join(base_path, \"trainLabels_cropped.csv\")\n",
        "\n",
        "print(\"Images folder: \", df_images)\n",
        "print(\"Labels file:\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_P0lhw6Us1OM"
      },
      "outputs": [],
      "source": [
        "# Loading the CSV\n",
        "df_labels = pd.read_csv(labels, header=0)\n",
        "print(df_labels.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9U3RtebBGR5"
      },
      "source": [
        "## 4. EDA (Exploratory Data Analysis) & Binary Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVUZoB6nBAz7"
      },
      "outputs": [],
      "source": [
        "#Number values\n",
        "images_files = os.listdir(df_images)\n",
        "\n",
        "print(f\"Number of images:\", {len(images_files)})\n",
        "print(f\"Number of inputs (labels):\", {len(df_labels)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsfjrvnytPD4"
      },
      "outputs": [],
      "source": [
        "# Reviewing the basic info\n",
        "df_labels.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-XIwF4Gy9JN"
      },
      "outputs": [],
      "source": [
        "# Droppng the unnamed:0 columns to minimise noise\n",
        "df_labels = df_labels.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"])\n",
        "print(df_labels.head(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg9nsnrc1Ysi"
      },
      "outputs": [],
      "source": [
        "df_labels.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_Ivx5sNvlUD"
      },
      "outputs": [],
      "source": [
        "# How many are missing?\n",
        "df_labels.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lvhp6CIZv8oD"
      },
      "outputs": [],
      "source": [
        "# How many are duplicated?\n",
        "df_labels.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGGoRoeQSV7B"
      },
      "source": [
        "## 5. Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIFMOBFmwX__"
      },
      "outputs": [],
      "source": [
        "df_num_columns = df_labels.select_dtypes(include=\"number\")\n",
        "df_num_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2WMjHP4tg95"
      },
      "outputs": [],
      "source": [
        "# How many classes?\n",
        "print(\"Unique labels\", df_labels['level'].unique())\n",
        "print(\"Class distribution:\\n\", df_labels[\"level\"].value_counts())\n",
        "print(\"Total:\", df_labels.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6-8_oyXrxR1C"
      },
      "outputs": [],
      "source": [
        "df_labels[\"level\"].value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"level of retinopathy\")\n",
        "plt.ylabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LqcaHQVu1I9"
      },
      "source": [
        "0 → no DR\n",
        "1 → mild\n",
        "2 → moderate\n",
        "3 → severe\n",
        "4 → proliferative\n",
        "\n",
        "I can see that the data is very imbalanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N8wUBmIxdRN"
      },
      "source": [
        "The data is very inbalanced. So the decision is to group 1, 2, 3, 4, together as 0: 'N0 DR',  1: 'Yes DR'.\n",
        "\n",
        "Solution:\n",
        "- Random under-sampling is useful but blunt.\n",
        "- Using moderate under-sampling + augmentation + class_weight is the gold standard.\n",
        "\n",
        "This ensures you don’t accidentally lose critical healthy examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wICOsz-f1vnG"
      },
      "outputs": [],
      "source": [
        "print(df_labels.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlYl8CUQyRHr"
      },
      "source": [
        "### Reviewing the **images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdnFEG_x3ayL"
      },
      "outputs": [],
      "source": [
        "# df_images = pd.read_csv(df_images)\n",
        "# print(df_labels.head())\n",
        "\n",
        "# Confirming folder variable\n",
        "print(\"Images folder path:\", df_images)\n",
        "print(\"Example files inside:\", os.listdir(df_images)[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fmhQUG0PyUHU"
      },
      "outputs": [],
      "source": [
        "# picking random images\n",
        "sample = df_labels.sample(10, random_state=42)\n",
        "\n",
        "# plotting 10 random samples side by side for better overview\n",
        "fig, axes = plt.subplots(1, 10, figsize=(20, 5))\n",
        "\n",
        "for ax, (_, row) in zip(axes, sample.iterrows()):\n",
        "    img_path = os.path.join(df_images, row['image'] + '.jpeg')\n",
        "    img = Image.open(img_path)\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(f\"Level: {row['level']}\")\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVq563IAJLwg"
      },
      "source": [
        "### Path Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KmbZYbr2QUv"
      },
      "outputs": [],
      "source": [
        "# Adding image path to the label Dataframe, this is the full path\n",
        "df_labels[\"path\"] = df_labels[\"image\"].apply(lambda x: os.path.join(df_images, x + \".jpeg\"))\n",
        "\n",
        "# I am only keeping the rows if they actually exist in the folder\n",
        "df_labels = df_labels[df_labels['path'].apply(os.path.exists)].copy()\n",
        "\n",
        "# Reviewing\n",
        "print(\"Rows with valid filles:\", len(df_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7eTVMyvOZAA"
      },
      "source": [
        "Now that we got 35108 back, we can see that we haven't lost any images or values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji-YY7gD4jKC"
      },
      "outputs": [],
      "source": [
        "# Function to enhance the images\n",
        "def enhance_retina_image(path, sigmaX=10):\n",
        "    image = cv2.imread(path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Could not read the image from path: {path}\")\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0, 0), sigmaX), -4, 128)\n",
        "\n",
        "    # Ensure valid float32 image in [0, 1]\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "\n",
        "    return image\n",
        "\n",
        "# Filtering positive cases (level > 0)\n",
        "df_positive = df_labels[df_labels['level'] > 0].reset_index(drop=True)\n",
        "\n",
        "# Example\n",
        "img_id = df_positive['image'].iloc[0]\n",
        "img_path = os.path.join(df_images, img_id + '.jpeg')\n",
        "\n",
        "# Define sigmaX values to compare\n",
        "sigma_values = [10, 15, 20, 30, 40]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(18, 4))\n",
        "\n",
        "# Keeping the original image\n",
        "original = cv2.imread(img_path)\n",
        "original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
        "original = cv2.resize(original, (224,224))\n",
        "\n",
        "plt.subplot(1, len(sigma_values) + 1, 1)\n",
        "plt.imshow(original)\n",
        "plt.axis('off')\n",
        "plt.title(\"Original\")\n",
        "\n",
        "# Enhancing the images\n",
        "for i, sigma in enumerate(sigma_values):\n",
        "    # Applying the enhancement\n",
        "    img = enhance_retina_image(img_path, sigmaX=sigma)\n",
        "    plt.subplot(1, len(sigma_values) + 1, i + 2)\n",
        "    plt.imshow(img, interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    plt.title(f'sigmaX = {sigma}')\n",
        "\n",
        "plt.suptitle(f'Original and Enhanced Versions of Image: {img_id}', fontsize=17)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIv1LjMa47dV"
      },
      "outputs": [],
      "source": [
        "# Picking random samples of 12 images\n",
        "sample_df = df_labels.sample(12, random_state=42)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, row in enumerate(sample_df.itertuples()):\n",
        "    try:\n",
        "        image = enhance_retina_image(row.path, sigmaX=10)\n",
        "        plt.subplot(3, 4, i + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Level:{row.level}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "plt.suptitle(f\"Enhanced Color Images\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"enhanced_images_grid.png\", dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "N4hXAQMrrx0q"
      },
      "outputs": [],
      "source": [
        "# Outputfolder, if the next line of code is giving an error to the path of the folder for processed images, uncomment everything and run it.\n",
        "output_dir = \"processed_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# Saving the enhanced images\n",
        "for row in df_labels.itertuples():\n",
        "  try:\n",
        "    enhanced_img = enhance_retina_image(row.path, sigmaX=10)\n",
        "    img_to_save = (enhanced_img *255).astype('uint8')\n",
        "    save_path = os.path.join(output_dir, f\"{row.image}.jpeg\")\n",
        "    plt.imsave(save_path, img_to_save)\n",
        "  except Exception as e:\n",
        "    print(f\"Skipping {row.image}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRTw7xr1K-Ah"
      },
      "outputs": [],
      "source": [
        "# Checking for some samples\n",
        "print(\"Sample files in processed_images folder:\")\n",
        "print(os.listdir(\"processed_images\")[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVxZ-h5nJlLb"
      },
      "outputs": [],
      "source": [
        "# Adding the processed image paths to the dataframe\n",
        "\n",
        "# Pointing to the processed folder\n",
        "processed_dir= \"processed_images\"\n",
        "\n",
        "# Adding processed images\n",
        "df_labels[\"processed_path\"] = df_labels[\"image\"].apply(\n",
        "    lambda x: os.path.join(processed_dir, f\"{x}.jpeg\")\n",
        ")\n",
        "\n",
        "# Filtering again to keep only valid files\n",
        "df_labels = df_labels[df_labels[\"processed_path\"].apply(os.path.exists)].copy()\n",
        "print(\"Processed images saved:\", len(df_labels))\n",
        "\n",
        "# Dropping the old path column if it exists\n",
        "if \"path\" in df_labels.columns:\n",
        "    df_labels.drop(columns=[\"path\"], inplace=True)\n",
        "\n",
        "# Renaming 'processed_path' to 'path' for compatibility with downstream code\n",
        "df_labels.rename(columns={\"processed_path\": \"path\"}, inplace=True)\n",
        "\n",
        "# Final check-up\n",
        "print(\"Total processed images retained:\", len(df_labels))\n",
        "df_labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bYBqxYcGla7"
      },
      "source": [
        "## 7. Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-Q-nECO-wO2"
      },
      "outputs": [],
      "source": [
        "# Adding Binary column by grouping 1, 2, 3, 4 together as 1 = 'Has DR', 0 = 'No DR'. - Data is very unbalanced.\n",
        "df_labels['binary_level'] = df_labels['level'].apply(lambda x: 0 if x ==0 else 1)\n",
        "print(df_labels[['level', 'binary_level']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPeNyuuT17C3"
      },
      "outputs": [],
      "source": [
        "# Plotting to check\n",
        "df_labels[\"binary_level\"].value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Retinopathy (0=N0, 1=YES,)\")\n",
        "plt.ylabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3SuVs5H2JYF"
      },
      "outputs": [],
      "source": [
        "print(df_labels.head(10))\n",
        "# print(df_labels.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC6rNI_wG8tY"
      },
      "source": [
        "## 8. Balance Dataset & Moderate Undersampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbOwubD_45lJ"
      },
      "source": [
        "### Moderate Undersampling\n",
        "I am going to moderately undersample the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQhXTnFA442d"
      },
      "outputs": [],
      "source": [
        "# Keep 2:1 (Moderate)\n",
        "df_healthy = df_labels[df_labels['binary_level'] == 0]\n",
        "df_dr = df_labels[df_labels['binary_level'] == 1]\n",
        "\n",
        "desired_healthy = 2 * len(df_dr)\n",
        "df_healthy_under = df_healthy.sample(desired_healthy, random_state=42)\n",
        "\n",
        "balanced_labels = pd.concat([df_healthy_under, df_dr]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "balanced_labels['binary_level'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuGKgTTv8eNd"
      },
      "source": [
        "I used moderate undersampling to keep the healthy class at twice the size of the DR-positive class, preserving useful healthy variation while reducing imbalance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSNbq1svBhVV"
      },
      "outputs": [],
      "source": [
        "# Reviewing Tensorflow version\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6YGH6MIS3R9"
      },
      "source": [
        "## 9. Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kyv8Ylbc94LX"
      },
      "outputs": [],
      "source": [
        "# Calculating the class_weight\n",
        "\n",
        "classes = np.unique(balanced_labels['binary_level'])\n",
        "weights = compute_class_weight(\n",
        "    class_weight = 'balanced',\n",
        "    classes = classes,\n",
        "    y=balanced_labels['binary_level']\n",
        ")\n",
        "class_weight = dict(zip(classes, weights))\n",
        "print(class_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1Guks7L--V9"
      },
      "source": [
        "np.int64(0): np.float64(0.75) --> healthy, gets weight 0.75\n",
        "np.int64(1): np.float64(1.5) --> gets weight 1.5\n",
        "\n",
        "- So if the model classifies a DR image --> the loss is multipliied by 1.5, which makes it more costly.\n",
        "- If it misclassifies a healthy image --> loss is multiplied by 0.75, which is less costly.\n",
        "In termsL It tells the model to pay extra attention to correctly detecting the DR.\n",
        "\n",
        "For further developing during the training, pass:\n",
        "- class_weight = {0: 0.75, 1: 1.5}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP7xeBFl_cfY"
      },
      "source": [
        "## 10. Train/Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzNbEnfa_DYi"
      },
      "outputs": [],
      "source": [
        "# Splitting it into 80% training and 20% validation (stratify to keep label balance)\n",
        "df_train, df_val = train_test_split(balanced_labels, test_size=0.2, stratify = balanced_labels['binary_level'], random_state=42)\n",
        "\n",
        "# Checking train dataframe\n",
        "print(\"Train:\")\n",
        "print(df_train['binary_level'].value_counts())\n",
        "\n",
        "# Checking for valudation\n",
        "print(\"\\nValidation:\")\n",
        "print(df_val['binary_level'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA33YCriPHQM"
      },
      "outputs": [],
      "source": [
        "# Convert labels back to integer type for tf.data\n",
        "df_train['binary_level'] = df_train['binary_level'].astype(int)\n",
        "df_val['binary_level'] = df_val['binary_level'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3byywM6NKgU"
      },
      "source": [
        "## 11. ImageDataGenerators\n",
        "Image generators for comparison and use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLOsgyEFLXZb"
      },
      "source": [
        "#### Defining the generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p-3FwctLVyY"
      },
      "outputs": [],
      "source": [
        "# Training with augementation\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 30,\n",
        "    zoom_range = 0.2,\n",
        "    brightness_range = [0.7, 1.3],\n",
        "    horizontal_flip =True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCHgzYrmMwSU"
      },
      "outputs": [],
      "source": [
        "# # Training with augmentation\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rescale=1./255,\n",
        "#     rotation_range=30,\n",
        "#     zoom_range=0.2,\n",
        "#     brightness_range=[0.7, 1.3],\n",
        "#     horizontal_flip=True\n",
        "# )\n",
        "\n",
        "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# # Convert binary_level column to string for flow_from_dataframe\n",
        "# df_train['binary_level'] = df_train['binary_level'].astype(str)\n",
        "# df_val['binary_level'] = df_val['binary_level'].astype(str)\n",
        "\n",
        "# train_generator = train_datagen.flow_from_dataframe(\n",
        "#     dataframe=df_train,\n",
        "#     directory=\"\", # Keep directory empty if paths are absolute or relative to the current working directory\n",
        "#     x_col='path',\n",
        "#     y_col='binary_level',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='binary',\n",
        "#     shuffle=True\n",
        "# )\n",
        "\n",
        "# val_generator = val_datagen.flow_from_dataframe(\n",
        "#     dataframe=df_val,\n",
        "#     directory=None, # Keep directory None if paths are absolute or relative to the current working directory\n",
        "#     x_col='path',\n",
        "#     y_col='binary_level',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='binary',\n",
        "#     shuffle=False\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRQ7isv4PrxX"
      },
      "source": [
        "What I did so far:\n",
        "\n",
        "1. Cleaned and prepared the dataset\n",
        "- dropped extra columns\n",
        "- verified I have 35108 valid image-label pairs\n",
        "- created a binary label: 0 = No DR, 1 = Has DR\n",
        "\n",
        "2. Used modeerate undersampling:\n",
        "- reduced the healthy class to twice the size of DR (2:1)\n",
        "- final count = healthy: 18.612,  DR: 9.306, Total: 27.918\n",
        "\n",
        "3. Calculated class weights:\n",
        "- {0: 0.75, 1: 1.5}\n",
        "- Model willpenalises DR mistakes more than healthy mistakes.\n",
        "\n",
        "4. Split into train/validation with stratify\n",
        "- 80% train: Healthy: 14,889, DR: 7,445\n",
        "- 20% validation: Healthy: 3,723, DR: 1,861\n",
        "\n",
        "5. Converted labels to strings\n",
        "- requrement by ImageDataGenerator\n",
        "\n",
        "6. Defined Generators:\n",
        "- train: uses augementations + rescaling\n",
        "- validation: only rescaling\n",
        "- Finding exat right number of images\n",
        "\n",
        "Found 22334 validated image filenames belonging to 2 classes for Train.\n",
        "\n",
        "Found 5584 validated image filenames belonging to 2 classes for validation.\n",
        "\n",
        "This matches the split.\n",
        "- 14,889 + 7,445 = 22,334 (train)\n",
        "- 3,723 + 1,861 = 5,584 (validation)\n",
        "\n",
        "\n",
        "Next step: Build and train the model\n",
        "1. EfficientNetB0 block + compile + train (with class_weight)?\n",
        "2. Also the custom CNN version side-by-side?\n",
        "3. Or only EfficientNet for now, one clean block?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqEPDSP1NyjG"
      },
      "source": [
        "## 12. Tf.data Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdM2MhmIDGL9"
      },
      "outputs": [],
      "source": [
        "# Turning the splits into tf.data.Dataset\n",
        "\n",
        "# Parsing function\n",
        "def parse_image(filename, label):\n",
        "  image = tf.io.read_file(filename)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.resize(image, [224, 224])\n",
        "  image = image / 255.0\n",
        "  return image, label\n",
        "\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhN7sNMvNwpe"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFTeJJxMEqOC"
      },
      "source": [
        "### Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo0urforEsEd"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((df_train['path'].values, df_train['binary_level'].values))\n",
        "train_ds = train_ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au0AMvFaFtUE"
      },
      "source": [
        "### Validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6Sl3c5tGaAk"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.data.Dataset.from_tensor_slices((df_val['path'].values, df_val['binary_level'].values))\n",
        "val_ds = val_ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jqBp21bHRrf"
      },
      "outputs": [],
      "source": [
        "# Inspecting 1 batch\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "  print(f\"Images shape:\", images.shape)\n",
        "  print(f\"Labels shape:\", df_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIYlIx3-NVug"
      },
      "source": [
        "### Computing class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEWo2MJZNdER"
      },
      "outputs": [],
      "source": [
        "# Get unique classes\n",
        "classes = np.unique(df_labels['binary_level'])\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "# computing weights\n",
        "weights = compute_class_weight(\n",
        "    class_weight = 'balanced',\n",
        "    classes = classes,\n",
        "    y = df_train['binary_level'].astype(int) # Changing it back to int because for class weight you need to have it in int.\n",
        ")\n",
        "\n",
        "# Making dictionary for Keras\n",
        "class_weight = dict(zip(classes, weights))\n",
        "print(\"Classweights:\", class_weight)\n",
        "\n",
        "# safe casting to plain int and float types\n",
        "class_weight = {int(k): float(v) for k, v, in class_weight.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVYMS5kxDyMY"
      },
      "source": [
        "### Defining Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzAGcJq6DwPv"
      },
      "outputs": [],
      "source": [
        "def binary_focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def focal_loss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1. - K.epsilon())  # avoid log(0)\n",
        "\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
        "        loss = -alpha_t * tf.pow(1 - p_t, gamma) * tf.math.log(p_t)\n",
        "\n",
        "        return tf.reduce_mean(loss)\n",
        "    return focal_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgY3qLoTPKyG"
      },
      "source": [
        "### Building & Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB4x_Q--P8aJ"
      },
      "outputs": [],
      "source": [
        "# Loading the basemodel\n",
        "base_model = EfficientNetB0(\n",
        "    input_shape = (224, 224, 3),\n",
        "    include_top = False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "# Building the full model\n",
        "inputs = layers.Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs, training = False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x) # for Binary classification output\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "# Compiling the model in the optimizer and loss function\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss= binary_focal_loss(gamma=2.0, alpha=0.25), #loss='binary_crossentropy',\n",
        "    metrics=['accuracy'] # e.g metrics['binary_accuracy']\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB_5t-Z_NHHT"
      },
      "source": [
        "Notes:\n",
        "- Adam is an SGD (Stochastic Gradient Descent) algorithm that has an adaptive learning rate that makes it suitable for most problems without any parameter tuning (it is 'self tuning', in a sense). Adam is a great general-purpose optimizer.\n",
        "\n",
        "- After I have defined the model, I added also a loss function, in this case 'binary_crossentropy', and Adam as optimizer.\n",
        "\n",
        "- Gradient is a vector that tells us in what direction the weights need to go. And more precisely, it tells us how to change the weights to make the loss change fastest. The reason why we call it process gradient descent, because it uses gradient to descend the loss curve towards a minimum, Stochastics means 'determinede by chance', the training is stochastic because the batches are random samples from the dataset, thus why it's called SGD.\n",
        "\n",
        "- Crosse-entropy function:\n",
        "The problem with accuracy (and most other classification metircs) is that it can't bee used as a loss function. SGD needs a loss function that changes smoothly, but accuracy, being a ratio of counts, changes in \"jumps\". So, we have to choose a substitute to act as the loss function. So in this case it is the cross-entropy function.\n",
        "- So for classification, what we want instead is a distance between probabilities, and this is what cross-entropy provides. Cross-entropy is a sort of measure for the distance from one probabillity distribution to another.\n",
        "- Ideally we want the netework to predict the correct class with a probability 1.0. The furuther away the predicted probability is from 1.0, the greater the cross-entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhkNXmZQbt8r"
      },
      "outputs": [],
      "source": [
        "# Turning the splits into tf.data.Dataset and updating the parse_image\n",
        "\n",
        "# Parsing function\n",
        "def parse_image(filename, label):\n",
        "  image = tf.io.read_file(filename)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.resize(image, [224, 224])\n",
        "  image = image / 255.0  # Rescale to [0, 1]\n",
        "\n",
        "  # Removed outdated conditional data augmentation logic\n",
        "\n",
        "  label = tf.cast(label, tf.float32)\n",
        "  return image, label\n",
        "\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0oB72kPWyjB"
      },
      "source": [
        "Notes: Smaller batch sizes give noisier weight updates and loss curves. The reason is because each batch is a small sample of data abd smaller samples tend to give noicier estimates. So smaller batches can have an averaging effect though which can be beneficial.\n",
        "\n",
        "Smaller learning rates makes the updates smaller and the training takes longer to converge. Large learning rates can speed up the training. Howeveer, when the leaerning rate is too large, the training can also completely fail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjnfo_vWdSVQ"
      },
      "outputs": [],
      "source": [
        "# Recreating the dataset, but now as INT\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((\n",
        "    df_train['path'].values,\n",
        "    df_train['binary_level'].values.astype(int) # Cast back to int here\n",
        "))\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((\n",
        "    df_val['path'].values,\n",
        "    df_val['binary_level'].values.astype(int) # Cast back to int here\n",
        "))\n",
        "\n",
        "train_ds = train_ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(1024).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = val_ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"tf.data datasets created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QvHpiKjOMUq"
      },
      "outputs": [],
      "source": [
        "# Unfreezing some layers of the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Fine-tuning with many layers onwards\n",
        "fine_tune_from = 100\n",
        "\n",
        "# Freezing layers before the 'fine_tune_from' layer\n",
        "for layer in base_model.layers[:fine_tune_from]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompiling the model with a lower learning rate for fine-tuning\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), # Even lower learning rate for fine-tuning\n",
        "    loss=binary_focal_loss(gamma=2.0, alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlrxGkT3POP-"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk9CAMc6VNk_"
      },
      "outputs": [],
      "source": [
        "# Adding the Callbacks\n",
        "early_stop = EarlyStopping(\n",
        "    monitor = 'val_loss',\n",
        "    patience= 5,  # how many epochs to wait before stopping\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "# Training the model using tf.data datasets\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop, checkpoint],\n",
        "    class_weight=class_weight # Applying class weights here\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhdyS7jsPeqF"
      },
      "source": [
        "### Evaluate\n",
        "\n",
        "When training the model, Keras provide updates on the loss as the model trains. So another way to view the loss is to simply plot it. The fit method keeps a record of the loss produced during training in a History object. So I'll convert the data to a Pandas dataframe, which makes the plotting easy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFn-WnojmbY9"
      },
      "outputs": [],
      "source": [
        "# Evaluating the Model\n",
        "\n",
        "results = model.evaluate(val_ds)\n",
        "print(f\"Validation Loss: {results[0]:.4f}\")\n",
        "print(f\"Validation Accuracy: {results[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_Q_LtkZ_giW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Get the true labels and predicted labels from the validation generator\n",
        "# The true labels are available directly from the generator\n",
        "y_true = val_generator.classes\n",
        "\n",
        "# Make predictions on the validation generator\n",
        "y_pred_probs = model.predict(val_generator)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a8LX6eRdcMI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwEoEXFkdcnq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqfY9-Jxm3dM"
      },
      "outputs": [],
      "source": [
        "# # Making predictions on a few examples\n",
        "\n",
        "# for images, labels in val_ds.take[1]:\n",
        "#   preds = model.predict(images)\n",
        "#   preds_binary = (preds >0.5).astype(int)\n",
        "#   print(\"Predictions: \", preds_binary.flatteen())\n",
        "#   print(\"True Labels: \", labels.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IZ4WPbrpz2n"
      },
      "source": [
        "- At least 10 epochs\n",
        "- confusion matrix\n",
        "\n",
        "\n",
        "- deadline 2 weeks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ffb962e"
      },
      "source": [
        "### Reason for changing the learning rate\n",
        "\n",
        "I reduced the learning rate of the Adam optimizer from its default to 0.0001 to help the model converge more effectively during training. The learning rate determines the size of the steps the optimizer takes when adjusting the model's weights to minimize the loss function.\n",
        "\n",
        "A high learning rate can cause the optimizer to take steps that are too large, potentially overshooting the optimal weights or causing the training process to become unstable, especially when using a custom loss function like Focal Loss. By using a smaller learning rate, I am allowing the optimizer to take smaller, more precise steps towards the minimum of the loss function, which can lead to better performance and a more stable training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy8Gq2rSZppC"
      },
      "source": [
        "### My Next Steps\n",
        "\n",
        "Now that I have a model with improved performance after implementing data augmentation and fine-tuning, here are the next steps I should consider:\n",
        "\n",
        "**What I have improved and changed:**\n",
        "\n",
        "*   **Handled Data Imbalance:** I used moderate undersampling and class weights to address the imbalance in the dataset.\n",
        "*   **Enhanced Images:** I applied an image enhancement function to preprocess the images.\n",
        "*   **Implemented Binary Classification:** I created a binary label (0 for No DR, 1 for Has DR).\n",
        "*   **Used TensorFlow Data Pipeline:** I utilized `tf.data.Dataset` for efficient data loading and preprocessing.\n",
        "*   **Applied Focal Loss:** I used a custom binary focal loss function to better handle the class imbalance during training.\n",
        "*   **Reduced Learning Rate:** I lowered the learning rate of the Adam optimizer to help the model converge.\n",
        "*   **Implemented Data Augmentation:** I added aggressive data augmentation to the training data pipeline.\n",
        "*   **Fine-tuned Base Model:** I unfroze and fine-tuned some layers of the EfficientNetB0 base model.\n",
        "\n",
        "**What I have done so far:**\n",
        "\n",
        "*   Loaded and cleaned the dataset.\n",
        "*   Performed exploratory data analysis.\n",
        "*   Split the data into training and validation sets.\n",
        "*   Built and compiled the EfficientNetB0 model.\n",
        "*   Trained the model and evaluated its initial performance.\n",
        "*   Troubleshooted data type issues in the data pipeline.\n",
        "*   Re-trained the model after implementing data augmentation and fine-tuning.\n",
        "*   Evaluated the improved model using the confusion matrix and classification report.\n",
        "\n",
        "**Here are my next steps:**\n",
        "\n",
        "1.  **Interpret the Classification Report in detail:** I need to carefully analyze the precision, recall, and F1-score for both the \"No DR\" (class 0) and \"Has DR\" (class 1) classes to understand the model's strengths and weaknesses for each.\n",
        "2.  **Visualize the Training History:** I should plot the accuracy and loss curves from the training history again to visually assess the training progress and look for signs of overfitting or underfitting.\n",
        "3.  **Experiment with different `fine_tune_from` values:** I can try unfreezing a different number of layers in the EfficientNetB0 base model during fine-tuning to see if it leads to further performance improvements.\n",
        "4.  **Consider adjusting the classification threshold:** Instead of using a default threshold of 0.5 for binary classification, I can explore if a different threshold improves the balance between precision and recall for the \"Has DR\" class, depending on the importance of minimizing false positives versus false negatives for this medical task.\n",
        "5.  **Potentially train for more epochs:** If the validation loss was still decreasing at the end of the last training run, I could try increasing the number of epochs or adjusting the Early Stopping patience to allow the model more time to converge.\n",
        "6.  **Evaluate on a separate test set:** Ideally, I should evaluate the final model on a completely separate test dataset that was not used during training or validation to get an unbiased estimate of its real-world performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77a02010"
      },
      "outputs": [],
      "source": [
        "# Converting the training history to a dataframe\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7373fab9"
      },
      "outputs": [],
      "source": [
        "# # Adding the Callbacks\n",
        "# early_stop = EarlyStopping(\n",
        "#     monitor = 'val_loss',\n",
        "#     patience= 5,  # how many epochs to wait before stopping\n",
        "#     restore_best_weights=True\n",
        "# )\n",
        "\n",
        "# checkpoint = ModelCheckpoint(\n",
        "#     'best_model.h5',\n",
        "#     monitor='val_loss',\n",
        "#     save_best_only=True\n",
        "# )\n",
        "\n",
        "# # Training the model using tf.data datasets\n",
        "# history = model.fit(\n",
        "#     train_ds,\n",
        "#     validation_data=val_ds,\n",
        "#     epochs=10,\n",
        "#     callbacks=[early_stop, checkpoint],\n",
        "#     class_weight=class_weight # Apply class weights here\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMnl6gGtn1/uUsthjsJt48H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}